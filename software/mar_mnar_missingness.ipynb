{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\RUSHI\\anaconda3\\envs\\tf\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import simulate\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "#import pypots\n",
    "from pypots.data import load_specific_dataset, mcar, masked_fill\n",
    "from pypots.imputation import SAITS\n",
    "from pypots.utils.metrics import cal_mae"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UCI HAR with MCAR, MAR, and MNAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_directory = \"D:/GitHub/ece209as_project/data/UCI_HAR_Dataset/train/Inertial_Signals/\"\n",
    "\n",
    "train_files = [\"body_acc_x_train.txt\", \"body_acc_y_train.txt\", \"body_acc_z_train.txt\", \n",
    "        \"body_gyro_x_train.txt\", \"body_gyro_y_train.txt\", \"body_gyro_z_train.txt\", \n",
    "        \"body_acc_x_train.txt\", \"body_acc_y_train.txt\", \"body_acc_z_train.txt\"]\n",
    "\n",
    "train_df = []\n",
    "train_y = pd.read_csv(\"D:/GitHub/ece209as_project/data/UCI_HAR_Dataset/train/y_train.txt\", header=None)\n",
    "\n",
    "test_directory = \"D:/GitHub/ece209as_project/data/UCI_HAR_Dataset/test/Inertial_Signals/\"\n",
    "\n",
    "test_files = [\"body_acc_x_test.txt\", \"body_acc_y_test.txt\", \"body_acc_z_test.txt\", \n",
    "        \"body_gyro_x_test.txt\", \"body_gyro_y_test.txt\", \"body_gyro_z_test.txt\", \n",
    "        \"body_acc_x_test.txt\", \"body_acc_y_test.txt\", \"body_acc_z_test.txt\"]\n",
    "\n",
    "test_df = []\n",
    "test_y = pd.read_csv(\"D:/GitHub/ece209as_project/data/UCI_HAR_Dataset/test/y_test.txt\", header=None)\n",
    "\n",
    "\n",
    "for train_file in train_files:\n",
    "    df = pd.read_csv(train_directory+train_file, delim_whitespace=True, header=None)\n",
    "    train_df.append(np.array(df))\n",
    "\n",
    "for test_file in test_files:\n",
    "    df = pd.read_csv(test_directory+test_file, delim_whitespace=True, header=None)\n",
    "    test_df.append(np.array(df))\n",
    "\n",
    "train_X = np.array(train_df).reshape([len(train_y), 128, 9])\n",
    "test_X = np.array(test_df).reshape([len(test_y), 128, 9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized successfully. Number of the trainable parameters: 1332038\n",
      "epoch 0: training loss 0.2265\n",
      "epoch 1: training loss 0.1341\n",
      "epoch 2: training loss 0.1171\n",
      "epoch 3: training loss 0.1090\n",
      "epoch 4: training loss 0.1041\n",
      "epoch 5: training loss 0.1004\n",
      "epoch 6: training loss 0.0978\n",
      "epoch 7: training loss 0.0957\n",
      "epoch 8: training loss 0.0939\n",
      "epoch 9: training loss 0.0926\n",
      "Finished training.\n"
     ]
    }
   ],
   "source": [
    "# MCAR\n",
    "dict_MCAR = simulate.simulate_nan(train_X, 0.1, \"MCAR\")\n",
    "X_intact_MCAR = dict_MCAR['X_init']\n",
    "X_missing_MCAR = dict_MCAR['X_incomp']\n",
    "X_mask_MCAR = dict_MCAR['mask']\n",
    "\n",
    "saits = SAITS(n_steps=128, n_features=9, n_layers=2, d_model=256, d_inner=128, n_head=4, d_k=64, d_v=64, dropout=0.1, epochs=10)\n",
    "saits.fit(X_missing_MCAR)\n",
    "imputation = saits.impute(X_missing_MCAR)\n",
    "mae = cal_mae(imputation, X_intact_MCAR, X_mask_MCAR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized successfully. Number of the trainable parameters: 1332038\n",
      "epoch 0: training loss 0.2259\n",
      "Finished training.\n"
     ]
    }
   ],
   "source": [
    "# MAR - logistic\n",
    "dict_MAR = simulate.simulate_nan(train_X, 0.1, \"MAR\")\n",
    "X_intact_MAR = dict_MAR['X_init']\n",
    "X_missing_MAR = dict_MAR['X_incomp']\n",
    "X_mask_MAR = dict_MAR['mask']\n",
    "\n",
    "saits = SAITS(n_steps=128, n_features=9, n_layers=2, d_model=256, d_inner=128, n_head=4, d_k=64, d_v=64, dropout=0.1, epochs=10)\n",
    "saits.fit(X_missing_MAR)\n",
    "imputation = saits.impute(X_missing_MAR)\n",
    "mae = cal_mae(imputation, X_intact_MAR, X_mask_MAR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized successfully. Number of the trainable parameters: 1332038\n",
      "epoch 0: training loss 0.2158\n",
      "Finished training.\n"
     ]
    }
   ],
   "source": [
    "# MNAR - logistic\n",
    "dict_MAR = simulate.simulate_nan(train_X, 0.1, \"MNAR\", opt=\"logistic\")\n",
    "X_intact_MNAR = dict_MAR['X_init']\n",
    "X_missing_MNAR = dict_MAR['X_incomp']\n",
    "X_mask_MNAR = dict_MAR['mask']\n",
    "\n",
    "saits = SAITS(n_steps=128, n_features=9, n_layers=2, d_model=256, d_inner=128, n_head=4, d_k=64, d_v=64, dropout=0.1, epochs=10)\n",
    "saits.fit(X_missing_MNAR)\n",
    "imputation = saits.impute(X_missing_MNAR)\n",
    "mae = cal_mae(imputation, X_intact_MNAR, X_mask_MNAR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PAMAPS2 with MCAR, MAR, and MNAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_directory = \"D:/GitHub/ece209as_project/data/PAMAP2_Dataset/Protocol\"\n",
    "\n",
    "train_files = \"/subject101.dat\"\n",
    "\n",
    "train_df = pd.read_csv(train_directory+train_files, delim_whitespace=True, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_Y = np.array(train_df[1])\n",
    "train_X = np.array(train_df.drop(columns=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createWindows(train_X, train_Y, window_size):\n",
    "    X = []\n",
    "    Y = []\n",
    "    i= 0\n",
    "\n",
    "    while i<len(train_X):\n",
    "        count = 0\n",
    "        j = i\n",
    "        while j<min(i+window_size, len(train_X)):\n",
    "            if(train_Y[int(j)] == train_Y[int(i)]):\n",
    "                count+=1\n",
    "            else:\n",
    "                break\n",
    "            j=j+1\n",
    "        if(count == window_size):\n",
    "            X.append(train_X[int(i):int(i+window_size)])\n",
    "            Y.append(train_Y[int(i)])\n",
    "            i+=(window_size/2)\n",
    "        else:\n",
    "            i=i+1\n",
    "\n",
    "    X = np.array(X)\n",
    "    Y = np.array(Y)\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 40\n",
    "X_40, Y_40 = createWindows(train_X, train_Y, window_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MCAR\n",
    "dict_MCAR = simulate.simulate_nan(X_40, 0.1, \"MCAR\")\n",
    "X_intact_MCAR = dict_MCAR['X_init']\n",
    "X_missing_MCAR = dict_MCAR['X_incomp']\n",
    "X_mask_MCAR = dict_MCAR['mask']\n",
    "\n",
    "\n",
    "saits = SAITS(n_steps=128, n_features=9, n_layers=2, d_model=256, d_inner=128, n_head=4, d_k=64, d_v=64, dropout=0.1, epochs=10)\n",
    "saits.fit(X_missing_MCAR)\n",
    "imputation = saits.impute(X_missing_MCAR)\n",
    "mae = cal_mae(imputation, X_intact_MCAR, X_mask_MCAR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAR - logistic\n",
    "dict_MAR = simulate.simulate_nan(X_40, 0.1, \"MAR\")\n",
    "X_intact_MAR = dict_MAR['X_init']\n",
    "X_missing_MAR = dict_MAR['X_incomp']\n",
    "X_mask_MAR = dict_MAR['mask']\n",
    "\n",
    "saits = SAITS(n_steps=128, n_features=9, n_layers=2, d_model=256, d_inner=128, n_head=4, d_k=64, d_v=64, dropout=0.1, epochs=10)\n",
    "saits.fit(X_missing_MAR)\n",
    "imputation = saits.impute(X_missing_MAR)\n",
    "mae = cal_mae(imputation, X_intact_MAR, X_mask_MAR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNAR - logistic\n",
    "dict_MAR = simulate.simulate_nan(X_40, 0.1, \"MNAR\", opt=\"logistic\")\n",
    "X_intact_MNAR = dict_MAR['X_init']\n",
    "X_missing_MNAR = dict_MAR['X_incomp']\n",
    "X_mask_MNAR = dict_MAR['mask']\n",
    "\n",
    "saits = SAITS(n_steps=128, n_features=9, n_layers=2, d_model=256, d_inner=128, n_head=4, d_k=64, d_v=64, dropout=0.1, epochs=10)\n",
    "saits.fit(X_missing_MNAR)\n",
    "imputation = saits.impute(X_missing_MNAR)\n",
    "mae = cal_mae(imputation, X_intact_MNAR, X_mask_MNAR)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "85eab4bc6c6c5de8d8c9b73424489217eb3ac6fe3bc76caf6b2eb1d4f520884f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('tf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
